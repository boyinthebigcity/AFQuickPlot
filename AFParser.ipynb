{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AFParser\n",
    "When importing .pkl files is too much for your computer to deal with (often with multimer predictions).\n",
    "\n",
    "If AFQuickPlot crashes, use this to create a .csv input file which can be plotted using AFRePlot.\n",
    "\n",
    "This can also minimise file sizes for long-term storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sorting through output folder files\n",
    "The folder should contain something like this:\n",
    "\n",
    "|&#128193; | | | |\n",
    "|---------------------|--------------------|----------------------|---------------------|\n",
    "|features.pkl         |ranked_1.pdb        |ranked_4.pdb          |relaxed_model_2.pdb  |\n",
    "|relaxed_model_5.pdb  |result_model_3.pkl  |timings.json          |unrelaxed_model_3.pdb|\n",
    "|msas                 |ranked_2.pdb        |ranking_debug.json    |relaxed_model_3.pdb  |\n",
    "|result_model_1.pkl   |result_model_4.pkl  |unrelaxed_model_1.pdb |unrelaxed_model_4.pdb|\n",
    "|ranked_0.pdb         |ranked_3.pdb        |relaxed_model_1.pdb   |relaxed_model_4.pdb  |\n",
    "|result_model_2.pkl   |result_model_5.pkl  |unrelaxed_model_2.pdb |unrelaxed_model_5.pdb|\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARG:\n",
    "    def __init__(self, repo):\n",
    "        self.input_dir = repo\n",
    "        self.output_dir = repo\n",
    "        self.name = name \n",
    "\n",
    "repo = [input('Please copy the path to your output folder (e.g. /Users/yourname/Documents/AFoutput ): ')] # This is a list of all output repositories\n",
    "name = input('Please enter the name of your protein: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in repo:\n",
    "    args = ARG(r)\n",
    "    with open(os.path.join(r, \"ranking_debug.json\"), 'r') as f:\n",
    "        ranking_dict = json.load(f)\n",
    "\n",
    "    feature_dict = pickle.load(open(f'{args.input_dir}/features.pkl','rb'))\n",
    "    is_multimer = ('result_model_3_multimer_v3_pred_0.pkl' in [os.path.basename(f) for f in os.listdir(path=args.input_dir)])\n",
    "    order=[]\n",
    "    for key in ranking_dict['order']:\n",
    "        order.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pae_plddt(model_dicts):\n",
    "    out = {}\n",
    "    for i,d in enumerate(model_dicts):\n",
    "        out[f'model_{i+1}'] = {'plddt': d['plddt'], \n",
    "                               'pae':d['predicted_aligned_error']}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting individual .pkl files into .csv files (can be plotted individually in AFRePlot)\n",
    "model_dicts=[]\n",
    "for r in repo:\n",
    "    for pred in order:\n",
    "        model_dict=[]\n",
    "        filename = \"result_\"+pred+\".pkl\"\n",
    "        with open(os.path.join(r,filename),'rb') as f:\n",
    "            model_dict=[pickle.load(f)]\n",
    "        pae_plddt_per_model=get_pae_plddt(model_dict)\n",
    "        plddts=[]\n",
    "        pae=[]\n",
    "        for key in pae_plddt_per_model.keys():\n",
    "            plddts.append(pae_plddt_per_model[key]['plddt'])\n",
    "            pae.append(pae_plddt_per_model[key]['pae'])\n",
    "\n",
    "        outname = pred+\"_plddt.csv\"\n",
    "        df_plddts = pd.DataFrame(plddts) \n",
    "        df_plddts.to_csv(os.path.join(args.output_dir if args.output_dir else args.input_dir,outname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining individual .csv files\n",
    "for r in repo:\n",
    "    i = 0\n",
    "    for pred in order:\n",
    "        outname = pred+\"_plddt.csv\"\n",
    "        file = pd.read_csv(os.path.join(args.input_dir,outname))\n",
    "        if i == 0:\n",
    "            pae_plddt = file.to_numpy()\n",
    "            print(i,pae_plddt.shape)\n",
    "        else:\n",
    "            npfile = file.to_numpy()\n",
    "            pae_plddt=np.vstack([pae_plddt,npfile])\n",
    "        i=i+1\n",
    "pae_plddt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_plddt = pd.DataFrame(pae_plddt)\n",
    "csvname = name+'_plddt.csv'\n",
    "combined_plddt.to_csv(os.path.join(os.path.join(args.output_dir if args.output_dir else args.input_dir,csvname)))\n",
    "combined_plddt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pae_plddt_per_model = get_pae_plddt(model_dicts)\n",
    "plddts=[]\n",
    "pae=[]\n",
    "for key in pae_plddt_per_model.keys():\n",
    "    plddts.append(pae_plddt_per_model[key]['plddt'])\n",
    "    pae.append(pae_plddt_per_model[key]['pae'])\n",
    "\n",
    "df_plddts = pd.DataFrame(plddts) \n",
    "df_plddts.to_csv(os.path.join(args.output_dir if args.output_dir else args.input_dir,r'plddt.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pae_plddt(model_dicts):\n",
    "    out = {}\n",
    "    for i,d in enumerate(model_dicts):\n",
    "        out[f'model_{i+1}'] = {'plddt': d['plddt'], \n",
    "                               'pae':d['predicted_aligned_error']}\n",
    "    return out\n",
    " \n",
    "def generate_output_images(feature_dict, model_dicts, ranking_dict, \n",
    "                           out_dir, name, pae_plddt_per_model):\n",
    "    msa = feature_dict['msa']\n",
    "    seqid = (np.array(msa[0] == msa).mean(-1))\n",
    "    seqid_sort = seqid.argsort()\n",
    "    non_gaps = (msa != 21).astype(float)\n",
    "    non_gaps[non_gaps == 0] = np.nan\n",
    "    final = non_gaps[seqid_sort] * seqid[seqid_sort, None]\n",
    "    #print(final)\n",
    "    ###################### PLOT MSA WITH COVERAGE ####################\n",
    "    \n",
    "    plt.figure(figsize=(14, 4), dpi=100)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f\"Sequence coverage ({name})\")\n",
    "    plt.imshow(final,\n",
    "               interpolation='nearest', aspect='auto',\n",
    "               cmap=\"rainbow_r\", vmin=0, vmax=1, origin='lower')\n",
    "    plt.plot((msa != 21).sum(0), color='black')\n",
    "    plt.xlim(-0.5, msa.shape[1]-0.5)\n",
    "    plt.ylim(-0.5, msa.shape[0]-0.5)\n",
    "    plt.colorbar(label=\"Sequence identity to query\")\n",
    "    plt.xlabel(\"Positions\")\n",
    "    plt.ylabel(\"Sequences\")\n",
    "    \n",
    "    ###################### PLOT LDDT PER POSITION ####################\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"Predicted LDDT per position ({name})\")\n",
    "    \n",
    "    colors = plt.cm.jet(np.linspace(0,1,len(pae_plddt_per_model)))\n",
    "    s = 0\n",
    "    for model_name, value in pae_plddt_per_model.items():\n",
    "        pltlabel = model_name.replace('model_','')\n",
    "        plt.plot(value[\"plddt\"], \n",
    "                 label=f\"{pltlabel}\",\n",
    "                 color=colors[s]) #, plddts: {round(list(ranking_dict['plddts'].values())[s], 6)}\")\n",
    "        s += 1\n",
    "    ax = plt.gca()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.05), bbox_transform=ax.transAxes, title=\"Model:\", fontsize=6)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xlim(-0.25, msa.shape[1]-0.75)\n",
    "    plt.ylabel(\"Predicted LDDT\")\n",
    "    plt.xlabel(\"Positions\")\n",
    "    plt.savefig(f\"{out_dir}/{name+('_' if name else '')}coverage_LDDT.pdf\")\n",
    " \n",
    "    ################# PLOT THE PREDICTED ALIGNED ERROR################\n",
    "    num_models = len(model_dicts)\n",
    "    plt.figure(figsize=(3 * num_models, 2), dpi=100)\n",
    "    for n, (model_name, value) in enumerate(pae_plddt_per_model.items()):\n",
    "        plt.subplot(1, num_models, n + 1)\n",
    "        plt.title(model_name)\n",
    "        plt.imshow(value[\"pae\"], label=model_name, cmap=\"bwr\", vmin=0, vmax=30)\n",
    "        plt.colorbar()\n",
    "    plt.savefig(f\"{out_dir}/{name+('_' if name else '')}PAE.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generating the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pae_plddt_per_model = get_pae_plddt(model_dicts)\n",
    "generate_output_images(feature_dict, model_dicts, ranking_dict, \n",
    "                       args.output_dir if args.output_dir else args.input_dir, \n",
    "                       args.name, pae_plddt_per_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Saving PAE and pLDDT scores as .csv \n",
    "This is an *optional* step, allowing you to save the PAE and pLDDT scores in a smaller file format. If you have limited storage space, this will allow you to delete the large .pkl files and re-plot prediction metrics later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plddts=[]\n",
    "pae=[]\n",
    "for key in pae_plddt_per_model.keys():\n",
    "    plddts.append(pae_plddt_per_model[key]['plddt'])\n",
    "    pae.append(pae_plddt_per_model[key]['pae'])\n",
    "\n",
    "df_plddts = pd.DataFrame(plddts) \n",
    "df_plddts.to_csv(os.path.join(args.output_dir if args.output_dir else args.input_dir,r'plddt.csv'))\n",
    "#df_pae = pd.DataFrame(pae) # 3-dimensional shape\n",
    "#df_pae.to_csv(os.path.join(args.output_dir if args.output_dir else args.input_dir,r'pae.csv'))\n",
    "#df = pd.DataFrame(pae_plddt_per_model)\n",
    "#df.to_csv(os.path.join(args.output_dir if args.output_dir else args.input_dir,r'pae_plddt.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
